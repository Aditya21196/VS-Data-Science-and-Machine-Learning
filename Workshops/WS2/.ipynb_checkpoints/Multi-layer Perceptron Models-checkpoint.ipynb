{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets module\n",
    "import sklearn.datasets as skd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_svmlight_format',\n",
       " 'base',\n",
       " 'california_housing',\n",
       " 'clear_data_home',\n",
       " 'covtype',\n",
       " 'dump_svmlight_file',\n",
       " 'fetch_20newsgroups',\n",
       " 'fetch_20newsgroups_vectorized',\n",
       " 'fetch_california_housing',\n",
       " 'fetch_covtype',\n",
       " 'fetch_kddcup99',\n",
       " 'fetch_lfw_pairs',\n",
       " 'fetch_lfw_people',\n",
       " 'fetch_mldata',\n",
       " 'fetch_olivetti_faces',\n",
       " 'fetch_rcv1',\n",
       " 'fetch_species_distributions',\n",
       " 'get_data_home',\n",
       " 'kddcup99',\n",
       " 'lfw',\n",
       " 'load_boston',\n",
       " 'load_breast_cancer',\n",
       " 'load_diabetes',\n",
       " 'load_digits',\n",
       " 'load_files',\n",
       " 'load_iris',\n",
       " 'load_linnerud',\n",
       " 'load_mlcomp',\n",
       " 'load_sample_image',\n",
       " 'load_sample_images',\n",
       " 'load_svmlight_file',\n",
       " 'load_svmlight_files',\n",
       " 'load_wine',\n",
       " 'make_biclusters',\n",
       " 'make_blobs',\n",
       " 'make_checkerboard',\n",
       " 'make_circles',\n",
       " 'make_classification',\n",
       " 'make_friedman1',\n",
       " 'make_friedman2',\n",
       " 'make_friedman3',\n",
       " 'make_gaussian_quantiles',\n",
       " 'make_hastie_10_2',\n",
       " 'make_low_rank_matrix',\n",
       " 'make_moons',\n",
       " 'make_multilabel_classification',\n",
       " 'make_regression',\n",
       " 'make_s_curve',\n",
       " 'make_sparse_coded_signal',\n",
       " 'make_sparse_spd_matrix',\n",
       " 'make_sparse_uncorrelated',\n",
       " 'make_spd_matrix',\n",
       " 'make_swiss_roll',\n",
       " 'mlcomp',\n",
       " 'mldata',\n",
       " 'mldata_filename',\n",
       " 'olivetti_faces',\n",
       " 'rcv1',\n",
       " 'samples_generator',\n",
       " 'species_distributions',\n",
       " 'svmlight_format',\n",
       " 'twenty_newsgroups']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkout the entities of this module\n",
    "dir(skd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling \"load_data\" as a function\n",
    "iris = skd.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'target', 'target_names']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking callable entities of this object now\n",
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the property: DESCR (stands for Description)\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick out the data\n",
    "xIris = iris.data\n",
    "yIris = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xIris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per our decided convention, we are going to take the number of sampes along axis = 1 (columns)\n",
    "X = xIris.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for output labels\n",
    "Y = yIris.reshape(1,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So effectively we have 150 samples for which we have input and output in corresponding indexes in X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 150)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have three unique output labels right now: 0,1 and 2. Since we are doing binary classification, let's filter out the 2 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing a 1-D filter\n",
    "idx = yIris <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the filter out\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the data\n",
    "Y = yIris[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data has only binary labels now\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 150)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter X as well\n",
    "X = X[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 100)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corresponding values of inputs have been chosen\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is not the required shape. Seems like after filtering, Y became uni dimensional. Let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.reshape(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn to standardize input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# We retain our scaler \"sc\" in case we need to invert our inputs\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.351023  ,  1.43136473,  1.35847229,  1.35865503,  1.3119249 ,\n",
       "         1.3198977 ,  1.29706355,  1.35489373,  1.37783158,  1.39536393,\n",
       "         1.35084454,  1.31697617,  1.4064146 ,  1.3331083 ,  1.34976381,\n",
       "         1.26369822,  1.32624394,  1.3600304 ,  1.37651426,  1.28853176,\n",
       "         1.4058958 ,  1.32061434,  1.24472875,  1.41746429,  1.29944317,\n",
       "         1.43733272,  1.37198868,  1.36370722,  1.38754866,  1.34715063,\n",
       "         1.38704608,  1.43087011,  1.22203598,  1.26214705,  1.39536393,\n",
       "         1.40591898,  1.40842139,  1.39536393,  1.35623308,  1.3703935 ,\n",
       "         1.34584928,  1.54277843,  1.30368712,  1.36838709,  1.28273619,\n",
       "         1.42848003,  1.27686857,  1.33807733,  1.33576544,  1.38019877,\n",
       "         1.42439522,  1.39427847,  1.38961667,  1.38472142,  1.40597899,\n",
       "         1.2729173 ,  1.34080392,  1.4124491 ,  1.39565142,  1.34856954,\n",
       "         1.40213637,  1.39472039,  1.42899153,  1.30649423,  1.45769298,\n",
       "         1.44687869,  1.26069096,  1.35764502,  1.39274612,  1.39397232,\n",
       "         1.26777854,  1.45240802,  1.31578947,  1.29118127,  1.42742816,\n",
       "         1.43990899,  1.39606955,  1.36370722,  1.34715063,  1.47186202,\n",
       "         1.40626103,  1.41645962,  1.42539329,  1.21283247,  1.21218305,\n",
       "         1.32376916,  1.40177016,  1.41154294,  1.33755249,  1.37783158,\n",
       "         1.25772013,  1.32438864,  1.40932853,  1.43721041,  1.3353007 ,\n",
       "         1.31954569,  1.34068463,  1.40021415,  1.51470512,  1.37150497],\n",
       "       [ 0.5033223 ,  0.3542982 ,  0.49136232,  0.45288501,  0.56225353,\n",
       "         0.54348729,  0.58144228,  0.47900284,  0.4276029 ,  0.3907019 ,\n",
       "         0.50031279,  0.5153385 ,  0.38356762,  0.53630794,  0.53990552,\n",
       "         0.65525093,  0.57553982,  0.49822896,  0.45071706,  0.59777247,\n",
       "         0.37404567,  0.55819782,  0.69151597,  0.37606196,  0.48181601,\n",
       "         0.31001294,  0.45732956,  0.4720525 ,  0.44506278,  0.45891944,\n",
       "         0.3942131 ,  0.38069021,  0.67890888,  0.64876717,  0.3907019 ,\n",
       "         0.43259046,  0.42864999,  0.3907019 ,  0.48325547,  0.45679783,\n",
       "         0.53018305,  0.12856487,  0.56748733,  0.48555671,  0.55771139,\n",
       "         0.36816496,  0.59236171,  0.50549588,  0.5215846 ,  0.45095603,\n",
       "        -0.42610113, -0.39039797, -0.49629167, -0.60678804, -0.55708601,\n",
       "        -0.46424043, -0.38926565, -0.35311228, -0.48213413, -0.42586406,\n",
       "        -0.57735027, -0.40291922, -0.58218174, -0.49169138, -0.2915386 ,\n",
       "        -0.41339391, -0.42023032, -0.3959798 , -0.74994022, -0.46465744,\n",
       "        -0.46538706, -0.42717883, -0.68421053, -0.48419297, -0.44023485,\n",
       "        -0.44506278, -0.56332631, -0.57695306, -0.48852715, -0.35324689,\n",
       "        -0.48913427, -0.45206158, -0.41573971, -0.64872435, -0.40406102,\n",
       "        -0.29590134, -0.46725672, -0.6604467 , -0.31846488, -0.52262577,\n",
       "        -0.5000574 , -0.44146288, -0.46977618, -0.41063155, -0.46580257,\n",
       "        -0.31851103, -0.38525421, -0.4297687 , -0.29597686, -0.41607454],\n",
       "       [-0.60928488, -0.55270519, -0.60697698, -0.51326968, -0.61580149,\n",
       "        -0.59524798, -0.61125984, -0.56111761, -0.52262577, -0.50233101,\n",
       "        -0.60037535, -0.5153385 , -0.5256297 , -0.62824644, -0.71987403,\n",
       "        -0.70205457, -0.72568064, -0.63288543, -0.57253248, -0.62434013,\n",
       "        -0.50302694, -0.6398853 , -0.74683725, -0.54962901, -0.3942131 ,\n",
       "        -0.47911091, -0.57166195, -0.57695306, -0.60214376, -0.48852715,\n",
       "        -0.48181601, -0.61698069, -0.60484609, -0.67235871, -0.50233101,\n",
       "        -0.64888568, -0.64909855, -0.50233101, -0.57678878, -0.56427968,\n",
       "        -0.66612742, -0.51425948, -0.59816232, -0.63269511, -0.50194025,\n",
       "        -0.57433733, -0.56603452, -0.56496598, -0.59791405, -0.58760938,\n",
       "         0.30435795,  0.33462683,  0.39703333,  0.45120136,  0.39791858,\n",
       "         0.55409341,  0.41810015,  0.28248982,  0.38063221,  0.42586406,\n",
       "         0.41239305,  0.34093165,  0.37047929,  0.51978803,  0.16196589,\n",
       "         0.25837119,  0.54953196,  0.3959798 ,  0.48210443,  0.37472374,\n",
       "         0.56167404,  0.2563073 ,  0.57894737,  0.53799219,  0.30683035,\n",
       "         0.2879818 ,  0.41637162,  0.4720525 ,  0.45891944,  0.17662344,\n",
       "         0.3668507 ,  0.33151183,  0.29695694,  0.70513516,  0.60609153,\n",
       "         0.38934387,  0.36342189,  0.42734786,  0.38215785,  0.4276029 ,\n",
       "         0.59097693,  0.46994436,  0.35233213,  0.27375436,  0.46580257,\n",
       "         0.40951418,  0.41607454,  0.34658766,  0.05223121,  0.38525421],\n",
       "       [-1.24506042, -1.23295773, -1.24285762, -1.29827036, -1.25837695,\n",
       "        -1.26813701, -1.267246  , -1.27277896, -1.28280871, -1.28373482,\n",
       "        -1.25078198, -1.31697617, -1.26435252, -1.2411698 , -1.1697953 ,\n",
       "        -1.21689458, -1.17610311, -1.22537392, -1.25469884, -1.2619641 ,\n",
       "        -1.27691454, -1.23892686, -1.18940747, -1.24389724, -1.38704608,\n",
       "        -1.26823475, -1.25765629, -1.25880667, -1.23046768, -1.31754292,\n",
       "        -1.29944317, -1.19457964, -1.29609877, -1.23855551, -1.28373482,\n",
       "        -1.18962375, -1.18797283, -1.28373482, -1.26269976, -1.26291166,\n",
       "        -1.20990491, -1.15708382, -1.27301212, -1.22124869, -1.33850733,\n",
       "        -1.22230765, -1.30319576, -1.27860722, -1.25943598, -1.24354543,\n",
       "        -1.30265204, -1.33850733, -1.29035833, -1.22913474, -1.24681156,\n",
       "        -1.36277029, -1.36963841, -1.34182665, -1.2941495 , -1.34856954,\n",
       "        -1.23717915, -1.33273281, -1.21728909, -1.33459088, -1.32812027,\n",
       "        -1.29185597, -1.3899926 , -1.35764502, -1.12491033, -1.30403863,\n",
       "        -1.36406552, -1.28153649, -1.21052632, -1.34498048, -1.29402366,\n",
       "        -1.28282801, -1.24911486, -1.25880667, -1.31754292, -1.29523858,\n",
       "        -1.28397747, -1.29590987, -1.30661052, -1.26924329, -1.41421356,\n",
       "        -1.41721169, -1.29793533, -1.1784441 , -1.40124546, -1.28280871,\n",
       "        -1.34863966, -1.35287012, -1.29188448, -1.30033323, -1.3353007 ,\n",
       "        -1.41054884, -1.37150497, -1.31703311, -1.27095947, -1.34068463]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X is now standardised\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.440892098500626e-18"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean 0\n",
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance is 1\n",
    "X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.6, 5. , 4.4, 4.9, 5.4, 4.8, 4.8,\n",
       "        4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5. ,\n",
       "        5. , 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5. , 5.5, 4.9, 4.4,\n",
       "        5.1, 5. , 4.5, 4.4, 5. , 5.1, 4.8, 5.1, 4.6, 5.3, 5. , 7. , 6.4,\n",
       "        6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5. , 5.9, 6. , 6.1, 5.6,\n",
       "        6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7,\n",
       "        6. , 5.7, 5.5, 5.5, 5.8, 6. , 5.4, 6. , 6.7, 6.3, 5.6, 5.5, 5.5,\n",
       "        6.1, 5.8, 5. , 5.6, 5.7, 5.7, 6.2, 5.1, 5.7],\n",
       "       [3.5, 3. , 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3. ,\n",
       "        3. , 4. , 4.4, 3.9, 3.5, 3.8, 3.8, 3.4, 3.7, 3.6, 3.3, 3.4, 3. ,\n",
       "        3.4, 3.5, 3.4, 3.2, 3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.1, 3. ,\n",
       "        3.4, 3.5, 2.3, 3.2, 3.5, 3.8, 3. , 3.8, 3.2, 3.7, 3.3, 3.2, 3.2,\n",
       "        3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2. , 3. , 2.2, 2.9, 2.9,\n",
       "        3.1, 3. , 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3. , 2.8, 3. ,\n",
       "        2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3. , 3.4, 3.1, 2.3, 3. , 2.5, 2.6,\n",
       "        3. , 2.6, 2.3, 2.7, 3. , 2.9, 2.9, 2.5, 2.8],\n",
       "       [1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4,\n",
       "        1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.5, 1.7, 1.5, 1. , 1.7, 1.9, 1.6,\n",
       "        1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, 1.5, 1.2, 1.3, 1.5, 1.3,\n",
       "        1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, 1.6, 1.4, 1.5, 1.4, 4.7, 4.5,\n",
       "        4.9, 4. , 4.6, 4.5, 4.7, 3.3, 4.6, 3.9, 3.5, 4.2, 4. , 4.7, 3.6,\n",
       "        4.4, 4.5, 4.1, 4.5, 3.9, 4.8, 4. , 4.9, 4.7, 4.3, 4.4, 4.8, 5. ,\n",
       "        4.5, 3.5, 3.8, 3.7, 3.9, 5.1, 4.5, 4.5, 4.7, 4.4, 4.1, 4. , 4.4,\n",
       "        4.6, 4. , 3.3, 4.2, 4.2, 4.2, 4.3, 3. , 4.1],\n",
       "       [0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1,\n",
       "        0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2,\n",
       "        0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.1, 0.2, 0.2, 0.1, 0.2,\n",
       "        0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, 1.4, 1.5,\n",
       "        1.5, 1.3, 1.5, 1.3, 1.6, 1. , 1.3, 1.4, 1. , 1.5, 1. , 1.4, 1.3,\n",
       "        1.4, 1.5, 1. , 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7,\n",
       "        1.5, 1. , 1.1, 1. , 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2,\n",
       "        1.4, 1.2, 1. , 1.3, 1.2, 1.3, 1.3, 1.1, 1.3]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using sc to revert the transformation\n",
    "sc.inverse_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of our network\n",
    "\n",
    "# number of inputs\n",
    "n0 = 4\n",
    "# number of hidden units\n",
    "n1 = 20\n",
    "# number of outputs\n",
    "n2 = 1\n",
    "# number of samples\n",
    "m = 100\n",
    "\n",
    "# We initialize our weights in a random normal fashion to aid the backpropagation\n",
    "W1 = np.random.randn(n1,n0) * 0.01\n",
    "W2 = np.random.randn(n2,n1) * 0.01\n",
    "\n",
    "# We may initailize the biases as 0 without hampering backpropagation\n",
    "B1 = np.zeros((n1,1))\n",
    "B2 = np.zeros((n2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good old sigmoid function\n",
    "def sigmoid(arr):\n",
    "    return 1/(1+np.exp(-arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propagation\n",
    "\n",
    "# As explained, the output of first layer can be obtained by taking the dot product of weights and inputs and then\n",
    "# broadcasting the biases\n",
    "Z1 = W1.dot(X) + B1\n",
    "# activating the first layer (the hidden layer)\n",
    "A1 = sigmoid(Z1)\n",
    "\n",
    "# The next layer uses output of previous layer as input\n",
    "Z2 = W2.dot(A1) + B2\n",
    "# The decision\n",
    "A2 = sigmoid(Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backprop\n",
    "\n",
    "# For sigmoid backprop and binary logloss, our derivative of cost w.r.t Z2 is:\n",
    "dZ2 = A2 - Y\n",
    "# This is a formula you guys will need to commit to memory or use as a reference. It requires quite a bit of work to derive\n",
    "dW2 = (1/m) * (dZ2.dot(A1.T))\n",
    "# Dervative of biases is usually just what derivative of weights is, excluding the multiplication with inputs from previous layer\n",
    "dB2 = (1/m) * (dZ2.mean(axis = 1,keepdims = True))\n",
    "\n",
    "# Another formula to remember dZ(of layer L) = W(of layer L).T.dot(dZ(L+1)) * derivative expression\n",
    "# The derivative expression for sigmoid is A1 * (1 - A1).\n",
    "# If the activation of this layer had been tanh, the derivative expression would have been (1 - A1**2)\n",
    "dZ1 = (W2.T).dot(dZ2) * A1 * (1 - A1)\n",
    "dW1 = (1/m) * (dZ1.dot(X.T))\n",
    "dB1 = (1/m) * (dZ1.mean(axis = 1,keepdims = True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating parameters\n",
    "lr = 0.01\n",
    "\n",
    "W1 = W1 - lr * dW1\n",
    "W2 = W2 - lr * dW2\n",
    "\n",
    "B1 = B1 - lr * dB1\n",
    "B2 = B2 - lr * dB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross entropy loss\n",
    "def logCost(A,Y):\n",
    "    return -(Y*np.log(A) + (1-Y)*np.log(1-A)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.32020142125276"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "logCost(A2,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re - initialization. We have tested stuff. We will now run the network from start.\n",
    "\n",
    "n0 = 4\n",
    "n1 = 1\n",
    "n2 = 1\n",
    "m = 100\n",
    "\n",
    "W1 = np.random.randn(n1,n0) * 0.01\n",
    "W2 = np.random.randn(n2,n1) * 0.01\n",
    "\n",
    "B1 = np.zeros((n1,1))\n",
    "B2 = np.zeros((n2,1))\n",
    "\n",
    "costs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 0 iterations is: 69.31405172755606\n",
      "cost after 50 iterations is: 51.299935575636205\n",
      "cost after 100 iterations is: 31.77656569163836\n",
      "cost after 150 iterations is: 26.287035704300415\n",
      "cost after 200 iterations is: 22.47868615668359\n",
      "cost after 250 iterations is: 19.551569995343243\n",
      "cost after 300 iterations is: 17.2245536526782\n",
      "cost after 350 iterations is: 15.337302739005448\n",
      "cost after 400 iterations is: 13.783016055057466\n",
      "cost after 450 iterations is: 12.486107559253574\n",
      "cost after 500 iterations is: 11.391389946224441\n",
      "cost after 550 iterations is: 10.457727250402018\n",
      "cost after 600 iterations is: 9.6539532393557\n",
      "cost after 650 iterations is: 8.956120592906258\n",
      "cost after 700 iterations is: 8.345594226536715\n",
      "cost after 750 iterations is: 7.807703320455867\n",
      "cost after 800 iterations is: 7.330773097668843\n",
      "cost after 850 iterations is: 6.905419708907707\n",
      "cost after 900 iterations is: 6.524030257153012\n",
      "cost after 950 iterations is: 6.18037487193314\n",
      "cost after 1000 iterations is: 5.869314133402442\n",
      "cost after 1050 iterations is: 5.5865761388502175\n",
      "cost after 1100 iterations is: 5.328584986060845\n",
      "cost after 1150 iterations is: 5.092327606173436\n",
      "cost after 1200 iterations is: 4.875249477100712\n",
      "cost after 1250 iterations is: 4.6751722866321765\n",
      "cost after 1300 iterations is: 4.490228423268805\n",
      "cost after 1350 iterations is: 4.318808474935611\n",
      "cost after 1400 iterations is: 4.159518861913835\n",
      "cost after 1450 iterations is: 4.011147424156221\n",
      "cost after 1500 iterations is: 3.8726352963334647\n",
      "cost after 1550 iterations is: 3.7430537866919398\n",
      "cost after 1600 iterations is: 3.621585263512221\n",
      "cost after 1650 iterations is: 3.5075072708803767\n",
      "cost after 1700 iterations is: 3.4001792617470037\n",
      "cost after 1750 iterations is: 3.299031463980934\n",
      "cost after 1800 iterations is: 3.2035554939074182\n",
      "cost after 1850 iterations is: 3.113296408701962\n",
      "cost after 1900 iterations is: 3.027845949211433\n",
      "cost after 1950 iterations is: 2.9468367721879267\n",
      "cost after 2000 iterations is: 2.869937508472974\n",
      "cost after 2050 iterations is: 2.796848513570584\n",
      "cost after 2100 iterations is: 2.7272982009787112\n",
      "cost after 2150 iterations is: 2.6610398678966063\n",
      "cost after 2200 iterations is: 2.5978489384794092\n",
      "cost after 2250 iterations is: 2.5375205624384467\n",
      "cost after 2300 iterations is: 2.4798675170802635\n",
      "cost after 2350 iterations is: 2.4247183693068988\n",
      "cost after 2400 iterations is: 2.3719158610291453\n",
      "cost after 2450 iterations is: 2.321315487163502\n",
      "cost after 2500 iterations is: 2.2727842401206524\n",
      "cost after 2550 iterations is: 2.226199498631992\n",
      "cost after 2600 iterations is: 2.181448042046365\n",
      "cost after 2650 iterations is: 2.1384251739798024\n",
      "cost after 2700 iterations is: 2.0970339415109196\n",
      "cost after 2750 iterations is: 2.0571844380605517\n",
      "cost after 2800 iterations is: 2.018793179738551\n",
      "cost after 2850 iterations is: 1.9817825463342509\n",
      "cost after 2900 iterations is: 1.9460802793112755\n",
      "cost after 2950 iterations is: 1.9116190301768703\n",
      "cost after 3000 iterations is: 1.8783359534581139\n",
      "cost after 3050 iterations is: 1.84617233925638\n",
      "cost after 3100 iterations is: 1.8150732809857182\n",
      "cost after 3150 iterations is: 1.7849873744472267\n",
      "cost after 3200 iterations is: 1.755866444862628\n",
      "cost after 3250 iterations is: 1.727665298898056\n",
      "cost after 3300 iterations is: 1.7003414990622772\n",
      "cost after 3350 iterations is: 1.6738551581706003\n",
      "cost after 3400 iterations is: 1.648168751832661\n",
      "cost after 3450 iterations is: 1.6232469471555466\n",
      "cost after 3500 iterations is: 1.599056446057112\n",
      "cost after 3550 iterations is: 1.5755658417627718\n",
      "cost after 3600 iterations is: 1.5527454872153805\n",
      "cost after 3650 iterations is: 1.5305673742652628\n",
      "cost after 3700 iterations is: 1.5090050226285199\n",
      "cost after 3750 iterations is: 1.488033377708315\n",
      "cost after 3800 iterations is: 1.467628716468203\n",
      "cost after 3850 iterations is: 1.4477685606299249\n",
      "cost after 3900 iterations is: 1.4284315965419727\n",
      "cost after 3950 iterations is: 1.4095976011308302\n",
      "cost after 4000 iterations is: 1.391247373405121\n",
      "cost after 4050 iterations is: 1.3733626710347455\n",
      "cost after 4100 iterations is: 1.3559261515734096\n",
      "cost after 4150 iterations is: 1.338921317934234\n",
      "cost after 4200 iterations is: 1.322332467765005\n",
      "cost after 4250 iterations is: 1.3061446464027953\n",
      "cost after 4300 iterations is: 1.2903436031171756\n",
      "cost after 4350 iterations is: 1.2749157503779245\n",
      "cost after 4400 iterations is: 1.2598481259070058\n",
      "cost after 4450 iterations is: 1.2451283572960286\n",
      "cost after 4500 iterations is: 1.2307446289898594\n",
      "cost after 4550 iterations is: 1.2166856514544355\n",
      "cost after 4600 iterations is: 1.2029406323626033\n",
      "cost after 4650 iterations is: 1.1894992496461072\n",
      "cost after 4700 iterations is: 1.1763516262746974\n",
      "cost after 4750 iterations is: 1.1634883066349682\n",
      "cost after 4800 iterations is: 1.1509002343922181\n",
      "cost after 4850 iterations is: 1.1385787317281937\n",
      "cost after 4900 iterations is: 1.1265154798562267\n",
      "cost after 4950 iterations is: 1.11470250072338\n",
      "cost after 5000 iterations is: 1.1031321398162925\n",
      "cost after 5050 iterations is: 1.091797049994104\n",
      "cost after 5100 iterations is: 1.0806901762777776\n",
      "cost after 5150 iterations is: 1.069804741530693\n",
      "cost after 5200 iterations is: 1.0591342329703175\n",
      "cost after 5250 iterations is: 1.0486723894554237\n",
      "cost after 5300 iterations is: 1.0384131894974533\n",
      "cost after 5350 iterations is: 1.028350839948496\n",
      "cost after 5400 iterations is: 1.0184797653219022\n",
      "cost after 5450 iterations is: 1.0087945977047106\n",
      "cost after 5500 iterations is: 0.9992901672241278\n",
      "cost after 5550 iterations is: 0.9899614930329523\n",
      "cost after 5600 iterations is: 0.9808037747813795\n",
      "cost after 5650 iterations is: 0.9718123845449389\n",
      "cost after 5700 iterations is: 0.9629828591804186\n",
      "cost after 5750 iterations is: 0.9543108930836158\n",
      "cost after 5800 iterations is: 0.9457923313245277\n",
      "cost after 5850 iterations is: 0.9374231631373408\n",
      "cost after 5900 iterations is: 0.9291995157439952\n",
      "cost after 5950 iterations is: 0.9211176484916735\n",
      "cost after 6000 iterations is: 0.9131739472857441\n",
      "cost after 6050 iterations is: 0.9053649193010236\n",
      "cost after 6100 iterations is: 0.8976871879552653\n",
      "cost after 6150 iterations is: 0.8901374881298901\n",
      "cost after 6200 iterations is: 0.8827126616239237\n",
      "cost after 6250 iterations is: 0.8754096528279527\n",
      "cost after 6300 iterations is: 0.868225504605904\n",
      "cost after 6350 iterations is: 0.8611573543730326\n",
      "cost after 6400 iterations is: 0.8542024303593599\n",
      "cost after 6450 iterations is: 0.8473580480484271\n",
      "cost after 6500 iterations is: 0.8406216067818895\n",
      "cost after 6550 iterations is: 0.8339905865209928\n",
      "cost after 6600 iterations is: 0.8274625447565914\n",
      "cost after 6650 iterations is: 0.821035113559803\n",
      "cost after 6700 iterations is: 0.8147059967659699\n",
      "cost after 6750 iterations is: 0.8084729672848766\n",
      "cost after 6800 iterations is: 0.8023338645307663\n",
      "cost after 6850 iterations is: 0.7962865919659405\n",
      "cost after 6900 iterations is: 0.7903291147521493\n",
      "cost after 6950 iterations is: 0.7844594575043403\n",
      "cost after 7000 iterations is: 0.7786757021415456\n",
      "cost after 7050 iterations is: 0.7729759858301283\n",
      "cost after 7100 iterations is: 0.767358499014733\n",
      "cost after 7150 iterations is: 0.7618214835326529\n",
      "cost after 7200 iterations is: 0.7563632308075339\n",
      "cost after 7250 iterations is: 0.7509820801185326\n",
      "cost after 7300 iterations is: 0.7456764169413002\n",
      "cost after 7350 iterations is: 0.7404446713573369\n",
      "cost after 7400 iterations is: 0.7352853165284705\n",
      "cost after 7450 iterations is: 0.7301968672333607\n",
      "cost after 7500 iterations is: 0.7251778784631372\n",
      "cost after 7550 iterations is: 0.7202269440733646\n",
      "cost after 7600 iterations is: 0.715342695489779\n",
      "cost after 7650 iterations is: 0.7105238004652655\n",
      "cost after 7700 iterations is: 0.7057689618857509\n",
      "cost after 7750 iterations is: 0.7010769166227937\n",
      "cost after 7800 iterations is: 0.696446434430745\n",
      "cost after 7850 iterations is: 0.6918763168864669\n",
      "cost after 7900 iterations is: 0.6873653963697474\n",
      "cost after 7950 iterations is: 0.6829125350825603\n",
      "cost after 8000 iterations is: 0.678516624105484\n",
      "cost after 8050 iterations is: 0.6741765824896402\n",
      "cost after 8100 iterations is: 0.6698913563826152\n",
      "cost after 8150 iterations is: 0.6656599181868809\n",
      "cost after 8200 iterations is: 0.6614812657493075\n",
      "cost after 8250 iterations is: 0.6573544215804807\n",
      "cost after 8300 iterations is: 0.6532784321024969\n",
      "cost after 8350 iterations is: 0.6492523669240848\n",
      "cost after 8400 iterations is: 0.6452753181418693\n",
      "cost after 8450 iterations is: 0.6413463996667061\n",
      "cost after 8500 iterations is: 0.6374647465740336\n",
      "cost after 8550 iterations is: 0.6336295144772679\n",
      "cost after 8600 iterations is: 0.6298398789232614\n",
      "cost after 8650 iterations is: 0.6260950348089758\n",
      "cost after 8700 iterations is: 0.6223941958184555\n",
      "cost after 8750 iterations is: 0.6187365938793187\n",
      "cost after 8800 iterations is: 0.6151214786379651\n",
      "cost after 8850 iterations is: 0.6115481169527661\n",
      "cost after 8900 iterations is: 0.6080157924045051\n",
      "cost after 8950 iterations is: 0.6045238048234145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 9000 iterations is: 0.6010714698321415\n",
      "cost after 9050 iterations is: 0.5976581184040086\n",
      "cost after 9100 iterations is: 0.5942830964360065\n",
      "cost after 9150 iterations is: 0.5909457643359327\n",
      "cost after 9200 iterations is: 0.5876454966231165\n",
      "cost after 9250 iterations is: 0.5843816815422673\n",
      "cost after 9300 iterations is: 0.5811537206898741\n",
      "cost after 9350 iterations is: 0.5779610286527295\n",
      "cost after 9400 iterations is: 0.5748030326581254\n",
      "cost after 9450 iterations is: 0.5716791722352643\n",
      "cost after 9500 iterations is: 0.5685888988874555\n",
      "cost after 9550 iterations is: 0.5655316757747574\n",
      "cost after 9600 iterations is: 0.5625069774066022\n",
      "cost after 9650 iterations is: 0.5595142893441108\n",
      "cost after 9700 iterations is: 0.556553107911684\n",
      "cost after 9750 iterations is: 0.5536229399175863\n",
      "cost after 9800 iterations is: 0.5507233023831574\n",
      "cost after 9850 iterations is: 0.5478537222803637\n",
      "cost after 9900 iterations is: 0.5450137362773873\n",
      "cost after 9950 iterations is: 0.5422028904919678\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "lr = 2\n",
    "\n",
    "for i in range(epochs):\n",
    "    # forward propagation\n",
    "\n",
    "    Z1 = W1.dot(X) + B1\n",
    "    A1 = sigmoid(Z1)\n",
    "\n",
    "    Z2 = W2.dot(A1) + B2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    # print cost\n",
    "    cost = logCost(A2,Y)\n",
    "    if i%50 == 0:\n",
    "        print(\"cost after\",str(i),\"iterations is:\",cost)\n",
    "    costs.append(cost)\n",
    "    \n",
    "    # backprop\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m) * (dZ2.dot(A1.T))\n",
    "    dB2 = (1/m) * (dZ2.mean(axis = 1,keepdims = True))\n",
    "\n",
    "    dZ1 = (W2.T).dot(dZ2) * A1 * (1 - A1)\n",
    "    dW1 = (1/m) * (dZ1.dot(X.T))\n",
    "    dB1 = (1/m) * (dZ1.mean(axis = 1,keepdims = True)) \n",
    "    \n",
    "    # weight update\n",
    "    W1 = W1 - lr * dW1\n",
    "    W2 = W2 - lr * dW2\n",
    "\n",
    "    B1 = B1 - lr * dB1\n",
    "    B2 = B2 - lr * dB2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost has reduced to lesser than 1 so results should be quite good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives an array of zeros\n",
    "pred = np.zeros(A2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just say whatever is closer to 0 is a 0 and whatever is closer to 1 is a 1\n",
    "pred[A2 > 0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perfect predictions!\n",
    "pred - Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have worked on binary classification, let's try multi-class classification as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the data\n",
    "iris = skd.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "xIris = iris.data\n",
    "yIris = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xIris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xIris.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# We will one hot encode the output labels since there are more than two categories\n",
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = yIris.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data\n",
    "ohe.fit(Y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial form\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "Y = ohe.transform(Y.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The convention which we are following requires the samples to be along columns so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 150)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization: This time we initialize parameters for multi-class classification\n",
    "\n",
    "n0 = 4\n",
    "n1 = 20\n",
    "# There are 3 outputs. Each will give a likelihood output being the corresponding category\n",
    "n2 = 3\n",
    "# number of samples is 150 now\n",
    "m = 150\n",
    "\n",
    "W1 = np.random.randn(n1,n0) * 0.01\n",
    "W2 = np.random.randn(n2,n1) * 0.01\n",
    "\n",
    "B1 = np.zeros((n1,1))\n",
    "B2 = np.zeros((n2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our cross entropy loss function\n",
    "def logCostMulti(A,Y):\n",
    "    assert A.shape == Y.shape\n",
    "    a,m = A.shape\n",
    "    \n",
    "    loss = -(Y * np.log(A)).sum()\n",
    "       \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the softmax function.\n",
    "def softmax(Z):\n",
    "    return np.exp(Z)/(np.exp(Z).sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 0 iterations is: 164.80316853252853\n",
      "cost after 500 iterations is: 42.28699666463442\n",
      "cost after 1000 iterations is: 20.033664176652522\n",
      "cost after 1500 iterations is: 14.636033462857725\n",
      "cost after 2000 iterations is: 12.436988813155255\n",
      "cost after 2500 iterations is: 11.26412313241101\n",
      "cost after 3000 iterations is: 10.54090859359587\n",
      "cost after 3500 iterations is: 10.052955041716906\n",
      "cost after 4000 iterations is: 9.702570446869787\n",
      "cost after 4500 iterations is: 9.439000767245108\n",
      "cost after 5000 iterations is: 9.233397719212443\n",
      "cost after 5500 iterations is: 9.068250555751048\n",
      "cost after 6000 iterations is: 8.932373685551466\n",
      "cost after 6500 iterations is: 8.818318683934594\n",
      "cost after 7000 iterations is: 8.720949574838553\n",
      "cost after 7500 iterations is: 8.636617760581409\n",
      "cost after 8000 iterations is: 8.562663781102966\n",
      "cost after 8500 iterations is: 8.497105413728185\n",
      "cost after 9000 iterations is: 8.438436131268055\n",
      "cost after 9500 iterations is: 8.385491139018825\n",
      "cost after 10000 iterations is: 8.337356058865549\n",
      "cost after 10500 iterations is: 8.293303272055914\n",
      "cost after 11000 iterations is: 8.252746648360718\n",
      "cost after 11500 iterations is: 8.215208772012213\n",
      "cost after 12000 iterations is: 8.180296832073179\n",
      "cost after 12500 iterations is: 8.147684628488781\n",
      "cost after 13000 iterations is: 8.117098965037362\n",
      "cost after 13500 iterations is: 8.088309235520162\n",
      "cost after 14000 iterations is: 8.0611193655968\n",
      "cost after 14500 iterations is: 8.0353615138031\n",
      "cost after 15000 iterations is: 8.010891101223267\n",
      "cost after 15500 iterations is: 7.987582855172834\n",
      "cost after 16000 iterations is: 7.965327634282737\n",
      "cost after 16500 iterations is: 7.944029861179925\n",
      "cost after 17000 iterations is: 7.923605431605699\n",
      "cost after 17500 iterations is: 7.903980000076402\n",
      "cost after 18000 iterations is: 7.885087565342327\n",
      "cost after 18500 iterations is: 7.866869296206989\n",
      "cost after 19000 iterations is: 7.849272551320426\n",
      "cost after 19500 iterations is: 7.832250056485255\n",
      "cost after 20000 iterations is: 7.815759210620499\n",
      "cost after 20500 iterations is: 7.799761497400885\n",
      "cost after 21000 iterations is: 7.784221984155044\n",
      "cost after 21500 iterations is: 7.769108893178757\n",
      "cost after 22000 iterations is: 7.754393233433656\n",
      "cost after 22500 iterations is: 7.740048482830364\n",
      "cost after 23000 iterations is: 7.7260503130712515\n",
      "cost after 23500 iterations is: 7.712376350450336\n",
      "cost after 24000 iterations is: 7.699005967153198\n",
      "cost after 24500 iterations is: 7.685920098526499\n",
      "cost after 25000 iterations is: 7.673101082539953\n",
      "cost after 25500 iterations is: 7.6605325182791155\n",
      "cost after 26000 iterations is: 7.648199140811583\n",
      "cost after 26500 iterations is: 7.636086710185346\n",
      "cost after 27000 iterations is: 7.624181912661222\n",
      "cost after 27500 iterations is: 7.612472272567234\n",
      "cost after 28000 iterations is: 7.600946073400209\n",
      "cost after 28500 iterations is: 7.589592286999\n",
      "cost after 29000 iterations is: 7.578400509780647\n",
      "cost after 29500 iterations is: 7.567360905171409\n",
      "cost after 30000 iterations is: 7.556464151483521\n",
      "cost after 30500 iterations is: 7.545701394589166\n",
      "cost after 31000 iterations is: 7.535064204828988\n",
      "cost after 31500 iterations is: 7.524544537665614\n",
      "cost after 32000 iterations is: 7.514134697655209\n",
      "cost after 32500 iterations is: 7.503827305363868\n",
      "cost after 33000 iterations is: 7.493615266902201\n",
      "cost after 33500 iterations is: 7.483491745791229\n",
      "cost after 34000 iterations is: 7.473450136907689\n",
      "cost after 34500 iterations is: 7.4634840422871145\n",
      "cost after 35000 iterations is: 7.453587248589388\n",
      "cost after 35500 iterations is: 7.443753706054887\n",
      "cost after 36000 iterations is: 7.433977508799692\n",
      "cost after 36500 iterations is: 7.4242528763165705\n",
      "cost after 37000 iterations is: 7.414574136064688\n",
      "cost after 37500 iterations is: 7.404935707045436\n",
      "cost after 38000 iterations is: 7.395332084275027\n",
      "cost after 38500 iterations is: 7.385757824076421\n",
      "cost after 39000 iterations is: 7.376207530124085\n",
      "cost after 39500 iterations is: 7.366675840185491\n",
      "cost after 40000 iterations is: 7.357157413512497\n",
      "cost after 40500 iterations is: 7.347646918845117\n",
      "cost after 41000 iterations is: 7.338139022998566\n",
      "cost after 41500 iterations is: 7.328628380013047\n",
      "cost after 42000 iterations is: 7.319109620853664\n",
      "cost after 42500 iterations is: 7.309577343656162\n",
      "cost after 43000 iterations is: 7.3000261045219315\n",
      "cost after 43500 iterations is: 7.290450408874019\n",
      "cost after 44000 iterations is: 7.280844703393647\n",
      "cost after 44500 iterations is: 7.271203368565366\n",
      "cost after 45000 iterations is: 7.2615207118668685\n",
      "cost after 45500 iterations is: 7.2517909616483855\n",
      "cost after 46000 iterations is: 7.242008261755023\n",
      "cost after 46500 iterations is: 7.232166666954342\n",
      "cost after 47000 iterations is: 7.2222601392403325\n",
      "cost after 47500 iterations is: 7.212282545094196\n",
      "cost after 48000 iterations is: 7.2022276537910646\n",
      "cost after 48500 iterations is: 7.192089136851125\n",
      "cost after 49000 iterations is: 7.181860568742262\n",
      "cost after 49500 iterations is: 7.171535428949615\n",
      "cost after 50000 iterations is: 7.161107105536005\n",
      "cost after 50500 iterations is: 7.150568900323685\n",
      "cost after 51000 iterations is: 7.139914035834865\n",
      "cost after 51500 iterations is: 7.129135664133219\n",
      "cost after 52000 iterations is: 7.118226877712219\n",
      "cost after 52500 iterations is: 7.107180722577848\n",
      "cost after 53000 iterations is: 7.095990213672668\n",
      "cost after 53500 iterations is: 7.0846483527847575\n",
      "cost after 54000 iterations is: 7.073148149078881\n",
      "cost after 54500 iterations is: 7.0614826423767\n",
      "cost after 55000 iterations is: 7.049644929299161\n",
      "cost after 55500 iterations is: 7.037628192364986\n",
      "cost after 56000 iterations is: 7.025425732115406\n",
      "cost after 56500 iterations is: 7.01303100230614\n",
      "cost after 57000 iterations is: 7.000437648172\n",
      "cost after 57500 iterations is: 6.987639547728435\n",
      "cost after 58000 iterations is: 6.974630856026202\n",
      "cost after 58500 iterations is: 6.961406052221774\n",
      "cost after 59000 iterations is: 6.94795998926503\n",
      "cost after 59500 iterations is: 6.934287945940386\n",
      "cost after 60000 iterations is: 6.9203856809255395\n",
      "cost after 60500 iterations is: 6.906249488456745\n",
      "cost after 61000 iterations is: 6.891876255110428\n",
      "cost after 61500 iterations is: 6.877263517130995\n",
      "cost after 62000 iterations is: 6.86240951765444\n",
      "cost after 62500 iterations is: 6.847313263099868\n",
      "cost after 63000 iterations is: 6.8319745779288965\n",
      "cost after 63500 iterations is: 6.816394156907776\n",
      "cost after 64000 iterations is: 6.800573613953399\n",
      "cost after 64500 iterations is: 6.7845155266037525\n",
      "cost after 65000 iterations is: 6.768223475130322\n",
      "cost after 65500 iterations is: 6.751702075305491\n",
      "cost after 66000 iterations is: 6.734957003856881\n",
      "cost after 66500 iterations is: 6.717995015683135\n",
      "cost after 67000 iterations is: 6.700823951974683\n",
      "cost after 67500 iterations is: 6.68345273847856\n",
      "cost after 68000 iterations is: 6.665891373269105\n",
      "cost after 68500 iterations is: 6.6481509035344715\n",
      "cost after 69000 iterations is: 6.630243391060934\n",
      "cost after 69500 iterations is: 6.612181866289249\n",
      "cost after 70000 iterations is: 6.59398027102602\n",
      "cost after 70500 iterations is: 6.575653390112475\n",
      "cost after 71000 iterations is: 6.557216772577449\n",
      "cost after 71500 iterations is: 6.538686643024274\n",
      "cost after 72000 iterations is: 6.520079804215035\n",
      "cost after 72500 iterations is: 6.501413532014088\n",
      "cost after 73000 iterations is: 6.482705464028257\n",
      "cost after 73500 iterations is: 6.4639734834284255\n",
      "cost after 74000 iterations is: 6.445235599549921\n",
      "cost after 74500 iterations is: 6.42650982694457\n",
      "cost after 75000 iterations is: 6.407814064591272\n",
      "cost after 75500 iterations is: 6.3891659769645255\n",
      "cost after 76000 iterations is: 6.370582878611183\n",
      "cost after 76500 iterations is: 6.3520816237972575\n",
      "cost after 77000 iterations is: 6.333678502661719\n",
      "cost after 77500 iterations is: 6.315389145158363\n",
      "cost after 78000 iterations is: 6.297228433885218\n",
      "cost after 78500 iterations is: 6.279210426699693\n",
      "cost after 79000 iterations is: 6.26134828980484\n",
      "cost after 79500 iterations is: 6.2436542417729015\n",
      "cost after 80000 iterations is: 6.226139508755187\n",
      "cost after 80500 iterations is: 6.208814290916848\n",
      "cost after 81000 iterations is: 6.19168773993814\n",
      "cost after 81500 iterations is: 6.174767947243772\n",
      "cost after 82000 iterations is: 6.15806194246305\n",
      "cost after 82500 iterations is: 6.1415757014882555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 83000 iterations is: 6.125314163388022\n",
      "cost after 83500 iterations is: 6.109281255347376\n",
      "cost after 84000 iterations is: 6.093479924745926\n",
      "cost after 84500 iterations is: 6.077912177449284\n",
      "cost after 85000 iterations is: 6.062579121374469\n",
      "cost after 85500 iterations is: 6.047481014395427\n",
      "cost after 86000 iterations is: 6.032617315677572\n",
      "cost after 86500 iterations is: 6.017986739567713\n",
      "cost after 87000 iterations is: 6.003587311214751\n",
      "cost after 87500 iterations is: 5.989416423155323\n",
      "cost after 88000 iterations is: 5.975470892163403\n",
      "cost after 88500 iterations is: 5.961747015732849\n",
      "cost after 89000 iterations is: 5.948240627633366\n",
      "cost after 89500 iterations is: 5.934947152053311\n",
      "cost after 90000 iterations is: 5.92186165591375\n",
      "cost after 90500 iterations is: 5.908978899007821\n",
      "cost after 91000 iterations is: 5.896293381684941\n",
      "cost after 91500 iterations is: 5.8837993898619505\n",
      "cost after 92000 iterations is: 5.8714910372000935\n",
      "cost after 92500 iterations is: 5.85936230433962\n",
      "cost after 93000 iterations is: 5.8474070751309615\n",
      "cost after 93500 iterations is: 5.835619169843737\n",
      "cost after 94000 iterations is: 5.823992375371697\n",
      "cost after 94500 iterations is: 5.812520472483987\n",
      "cost after 95000 iterations is: 5.801197260200121\n",
      "cost after 95500 iterations is: 5.790016577388953\n",
      "cost after 96000 iterations is: 5.778972321710224\n",
      "cost after 96500 iterations is: 5.768058466031926\n",
      "cost after 97000 iterations is: 5.757269072467553\n",
      "cost after 97500 iterations is: 5.746598304185188\n",
      "cost after 98000 iterations is: 5.736040435145046\n",
      "cost after 98500 iterations is: 5.725589857924334\n",
      "cost after 99000 iterations is: 5.715241089788528\n",
      "cost after 99500 iterations is: 5.7049887771660135\n",
      "cost after 100000 iterations is: 5.694827698679652\n",
      "cost after 100500 iterations is: 5.684752766883992\n",
      "cost after 101000 iterations is: 5.674759028850781\n",
      "cost after 101500 iterations is: 5.664841665738716\n",
      "cost after 102000 iterations is: 5.6549959914758645\n",
      "cost after 102500 iterations is: 5.645217450675253\n",
      "cost after 103000 iterations is: 5.635501615896015\n",
      "cost after 103500 iterations is: 5.625844184354078\n",
      "cost after 104000 iterations is: 5.616240974178204\n",
      "cost after 104500 iterations is: 5.606687920298704\n",
      "cost after 105000 iterations is: 5.597181070048628\n",
      "cost after 105500 iterations is: 5.587716578549062\n",
      "cost after 106000 iterations is: 5.578290703943146\n",
      "cost after 106500 iterations is: 5.568899802536313\n",
      "cost after 107000 iterations is: 5.559540323893844\n",
      "cost after 107500 iterations is: 5.550208805940688\n",
      "cost after 108000 iterations is: 5.540901870102994\n",
      "cost after 108500 iterations is: 5.531616216525709\n",
      "cost after 109000 iterations is: 5.522348619395814\n",
      "cost after 109500 iterations is: 5.513095922396938\n",
      "cost after 110000 iterations is: 5.503855034316957\n",
      "cost after 110500 iterations is: 5.494622924827251\n",
      "cost after 111000 iterations is: 5.4853966204492615\n",
      "cost after 111500 iterations is: 5.476173200721481\n",
      "cost after 112000 iterations is: 5.466949794577876\n",
      "cost after 112500 iterations is: 5.457723576947038\n",
      "cost after 113000 iterations is: 5.448491765579568\n",
      "cost after 113500 iterations is: 5.439251618110165\n",
      "cost after 114000 iterations is: 5.430000429359678\n",
      "cost after 114500 iterations is: 5.420735528881659\n",
      "cost after 115000 iterations is: 5.411454278757093\n",
      "cost after 115500 iterations is: 5.402154071640618\n",
      "cost after 116000 iterations is: 5.392832329060976\n",
      "cost after 116500 iterations is: 5.3834864999781535\n",
      "cost after 117000 iterations is: 5.374114059599353\n",
      "cost after 117500 iterations is: 5.3647125084556055\n",
      "cost after 118000 iterations is: 5.355279371740801\n",
      "cost after 118500 iterations is: 5.345812198914374\n",
      "cost after 119000 iterations is: 5.336308563568804\n",
      "cost after 119500 iterations is: 5.326766063562678\n",
      "cost after 120000 iterations is: 5.317182321419772\n",
      "cost after 120500 iterations is: 5.3075549849939465\n",
      "cost after 121000 iterations is: 5.297881728399345\n",
      "cost after 121500 iterations is: 5.288160253204546\n",
      "cost after 122000 iterations is: 5.278388289888719\n",
      "cost after 122500 iterations is: 5.268563599556816\n",
      "cost after 123000 iterations is: 5.258683975909971\n",
      "cost after 123500 iterations is: 5.248747247466144\n",
      "cost after 124000 iterations is: 5.238751280024751\n",
      "cost after 124500 iterations is: 5.228693979367806\n",
      "cost after 125000 iterations is: 5.218573294188525\n",
      "cost after 125500 iterations is: 5.208387219236858\n",
      "cost after 126000 iterations is: 5.198133798669782\n",
      "cost after 126500 iterations is: 5.187811129592307\n",
      "cost after 127000 iterations is: 5.177417365773636\n",
      "cost after 127500 iterations is: 5.166950721520719\n",
      "cost after 128000 iterations is: 5.156409475689876\n",
      "cost after 128500 iterations is: 5.145791975815193\n",
      "cost after 129000 iterations is: 5.135096642330474\n",
      "cost after 129500 iterations is: 5.124321972859888\n",
      "cost after 130000 iterations is: 5.113466546550758\n",
      "cost after 130500 iterations is: 5.102529028420207\n",
      "cost after 131000 iterations is: 5.091508173686165\n",
      "cost after 131500 iterations is: 5.0804028320518215\n",
      "cost after 132000 iterations is: 5.0692119519118215\n",
      "cost after 132500 iterations is: 5.057934584447388\n",
      "cost after 133000 iterations is: 5.046569887577442\n",
      "cost after 133500 iterations is: 5.03511712973235\n",
      "cost after 134000 iterations is: 5.023575693417079\n",
      "cost after 134500 iterations is: 5.011945078531189\n",
      "cost after 135000 iterations is: 5.000224905413686\n",
      "cost after 135500 iterations is: 4.988414917582302\n",
      "cost after 136000 iterations is: 4.9765149841378475\n",
      "cost after 136500 iterations is: 4.964525101806789\n",
      "cost after 137000 iterations is: 4.952445396597159\n",
      "cost after 137500 iterations is: 4.940276125045521\n",
      "cost after 138000 iterations is: 4.928017675035962\n",
      "cost after 138500 iterations is: 4.915670566174962\n",
      "cost after 139000 iterations is: 4.903235449709879\n",
      "cost after 139500 iterations is: 4.890713107982024\n",
      "cost after 140000 iterations is: 4.878104453409615\n",
      "cost after 140500 iterations is: 4.865410526999609\n",
      "cost after 141000 iterations is: 4.852632496391502\n",
      "cost after 141500 iterations is: 4.8397716534401365\n",
      "cost after 142000 iterations is: 4.826829411348719\n",
      "cost after 142500 iterations is: 4.813807301366988\n",
      "cost after 143000 iterations is: 4.800706969073024\n",
      "cost after 143500 iterations is: 4.787530170260954\n",
      "cost after 144000 iterations is: 4.774278766459803\n",
      "cost after 144500 iterations is: 4.760954720111703\n",
      "cost after 145000 iterations is: 4.747560089440181\n",
      "cost after 145500 iterations is: 4.734097023041469\n",
      "cost after 146000 iterations is: 4.720567754233533\n",
      "cost after 146500 iterations is: 4.706974595198749\n",
      "cost after 147000 iterations is: 4.693319930957304\n",
      "cost after 147500 iterations is: 4.679606213208675\n",
      "cost after 148000 iterations is: 4.6658359540786565\n",
      "cost after 148500 iterations is: 4.652011719809169\n",
      "cost after 149000 iterations is: 4.638136124427221\n",
      "cost after 149500 iterations is: 4.6242118234283325\n",
      "cost after 150000 iterations is: 4.610241507508344\n",
      "cost after 150500 iterations is: 4.596227896375762\n",
      "cost after 151000 iterations is: 4.5821737326747325\n",
      "cost after 151500 iterations is: 4.56808177604667\n",
      "cost after 152000 iterations is: 4.553954797356012\n",
      "cost after 152500 iterations is: 4.539795573103116\n",
      "cost after 153000 iterations is: 4.5256068800446405\n",
      "cost after 153500 iterations is: 4.51139149003915\n",
      "cost after 154000 iterations is: 4.4971521651328\n",
      "cost after 154500 iterations is: 4.482891652897399\n",
      "cost after 155000 iterations is: 4.468612682030582\n",
      "cost after 155500 iterations is: 4.454317958224965\n",
      "cost after 156000 iterations is: 4.440010160311134\n",
      "cost after 156500 iterations is: 4.425691936676594\n",
      "cost after 157000 iterations is: 4.411365901960929\n",
      "cost after 157500 iterations is: 4.397034634025296\n",
      "cost after 158000 iterations is: 4.382700671192605\n",
      "cost after 158500 iterations is: 4.368366509752974\n",
      "cost after 159000 iterations is: 4.354034601727905\n",
      "cost after 159500 iterations is: 4.3397073528849015\n",
      "cost after 160000 iterations is: 4.32538712099365\n",
      "cost after 160500 iterations is: 4.3110762143137\n",
      "cost after 161000 iterations is: 4.296776890302933\n",
      "cost after 161500 iterations is: 4.282491354535589\n",
      "cost after 162000 iterations is: 4.268221759818222\n",
      "cost after 162500 iterations is: 4.253970205491741\n",
      "cost after 163000 iterations is: 4.239738736907398\n",
      "cost after 163500 iterations is: 4.225529345064974\n",
      "cost after 164000 iterations is: 4.211343966401071\n",
      "cost after 164500 iterations is: 4.197184482715934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 165000 iterations is: 4.183052721227546\n",
      "cost after 165500 iterations is: 4.1689504547417515\n",
      "cost after 166000 iterations is: 4.154879401928068\n",
      "cost after 166500 iterations is: 4.140841227690925\n",
      "cost after 167000 iterations is: 4.126837543626709\n",
      "cost after 167500 iterations is: 4.1128699085575615\n",
      "cost after 168000 iterations is: 4.098939829133405\n",
      "cost after 168500 iterations is: 4.085048760494077\n",
      "cost after 169000 iterations is: 4.071198106984241\n",
      "cost after 169500 iterations is: 4.057389222914069\n",
      "cost after 170000 iterations is: 4.0436234133594295\n",
      "cost after 170500 iterations is: 4.029901934995597\n",
      "cost after 171000 iterations is: 4.016225996959269\n",
      "cost after 171500 iterations is: 4.002596761733949\n",
      "cost after 172000 iterations is: 3.989015346054307\n",
      "cost after 172500 iterations is: 3.975482821825533\n",
      "cost after 173000 iterations is: 3.9620002170541513\n",
      "cost after 173500 iterations is: 3.9485685167870663\n",
      "cost after 174000 iterations is: 3.93518866405602\n",
      "cost after 174500 iterations is: 3.9218615608249086\n",
      "cost after 175000 iterations is: 3.908588068937811\n",
      "cost after 175500 iterations is: 3.895369011065676\n",
      "cost after 176000 iterations is: 3.8822051716500465\n",
      "cost after 176500 iterations is: 3.869097297842317\n",
      "cost after 177000 iterations is: 3.8560461004371107\n",
      "cost after 177500 iterations is: 3.843052254798934\n",
      "cost after 178000 iterations is: 3.830116401780779\n",
      "cost after 178500 iterations is: 3.817239148634176\n",
      "cost after 179000 iterations is: 3.8044210699097754\n",
      "cost after 179500 iterations is: 3.7916627083479786\n",
      "cost after 180000 iterations is: 3.778964575758997\n",
      "cost after 180500 iterations is: 3.766327153891949\n",
      "cost after 181000 iterations is: 3.7537508952926593\n",
      "cost after 181500 iterations is: 3.741236224149718\n",
      "cost after 182000 iterations is: 3.728783537128585\n",
      "cost after 182500 iterations is: 3.716393204193518\n",
      "cost after 183000 iterations is: 3.7040655694169815\n",
      "cost after 183500 iterations is: 3.691800951776494\n",
      "cost after 184000 iterations is: 3.6795996459385734\n",
      "cost after 184500 iterations is: 3.6674619230296974\n",
      "cost after 185000 iterations is: 3.6553880313941205\n",
      "cost after 185500 iterations is: 3.6433781973382504\n",
      "cost after 186000 iterations is: 3.6314326258616543\n",
      "cost after 186500 iterations is: 3.6195515013742767\n",
      "cost after 187000 iterations is: 3.6077349883999372\n",
      "cost after 187500 iterations is: 3.5959832322658065\n",
      "cost after 188000 iterations is: 3.5842963597777073\n",
      "cost after 188500 iterations is: 3.572674479881194\n",
      "cost after 189000 iterations is: 3.5611176843081127\n",
      "cost after 189500 iterations is: 3.5496260482085216\n",
      "cost after 190000 iterations is: 3.5381996307678283\n",
      "cost after 190500 iterations is: 3.526838475809063\n",
      "cost after 191000 iterations is: 3.515542612379905\n",
      "cost after 191500 iterations is: 3.5043120553245464\n",
      "cost after 192000 iterations is: 3.4931468058401385\n",
      "cost after 192500 iterations is: 3.482046852017706\n",
      "cost after 193000 iterations is: 3.4710121693674076\n",
      "cost after 193500 iterations is: 3.460042721327926\n",
      "cost after 194000 iterations is: 3.449138459760184\n",
      "cost after 194500 iterations is: 3.4382993254248735\n",
      "cost after 195000 iterations is: 3.427525248444155\n",
      "cost after 195500 iterations is: 3.416816148747067\n",
      "cost after 196000 iterations is: 3.406171936499077\n",
      "cost after 196500 iterations is: 3.3955925125152544\n",
      "cost after 197000 iterations is: 3.385077768657609\n",
      "cost after 197500 iterations is: 3.374627588216126\n",
      "cost after 198000 iterations is: 3.364241846274052\n",
      "cost after 198500 iterations is: 3.35392041005704\n",
      "cost after 199000 iterations is: 3.34366313926675\n",
      "cost after 199500 iterations is: 3.3334698863987002\n",
      "cost after 200000 iterations is: 3.323340497044715\n",
      "cost after 200500 iterations is: 3.313274810180117\n",
      "cost after 201000 iterations is: 3.3032726584360197\n",
      "cost after 201500 iterations is: 3.2933338683568314\n",
      "cost after 202000 iterations is: 3.283458260643332\n",
      "cost after 202500 iterations is: 3.2736456503817366\n",
      "cost after 203000 iterations is: 3.263895847258957\n",
      "cost after 203500 iterations is: 3.254208655764622\n",
      "cost after 204000 iterations is: 3.2445838753800267\n",
      "cost after 204500 iterations is: 3.2350213007547177\n",
      "cost after 205000 iterations is: 3.2255207218710376\n",
      "cost after 205500 iterations is: 3.216081924196978\n",
      "cost after 206000 iterations is: 3.206704688828277\n",
      "cost after 206500 iterations is: 3.1973887926196816\n",
      "cost after 207000 iterations is: 3.1881340083064442\n",
      "cost after 207500 iterations is: 3.1789401046163137\n",
      "cost after 208000 iterations is: 3.169806846372677\n",
      "cost after 208500 iterations is: 3.160733994589382\n",
      "cost after 209000 iterations is: 3.151721306557884\n",
      "cost after 209500 iterations is: 3.142768535927242\n",
      "cost after 210000 iterations is: 3.133875432777546\n",
      "cost after 210500 iterations is: 3.125041743687396\n",
      "cost after 211000 iterations is: 3.1162672117959787\n",
      "cost after 211500 iterations is: 3.107551576860335\n",
      "cost after 212000 iterations is: 3.098894575308311\n",
      "cost after 212500 iterations is: 3.090295940287831\n",
      "cost after 213000 iterations is: 3.0817554017129956\n",
      "cost after 213500 iterations is: 3.073272686307438\n",
      "cost after 214000 iterations is: 3.064847517645627\n",
      "cost after 214500 iterations is: 3.0564796161922634\n",
      "cost after 215000 iterations is: 3.0481686993407093\n",
      "cost after 215500 iterations is: 3.039914481450338\n",
      "cost after 216000 iterations is: 3.0317166738836434\n",
      "cost after 216500 iterations is: 3.0235749850432168\n",
      "cost after 217000 iterations is: 3.0154891204091068\n",
      "cost after 217500 iterations is: 3.007458782576809\n",
      "cost after 218000 iterations is: 2.999483671296059\n",
      "cost after 218500 iterations is: 2.9915634835110567\n",
      "cost after 219000 iterations is: 2.983697913401942\n",
      "cost after 219500 iterations is: 2.9758866524279606\n",
      "cost after 220000 iterations is: 2.9681293893723817\n",
      "cost after 220500 iterations is: 2.9604258103895686\n",
      "cost after 221000 iterations is: 2.952775599053958\n",
      "cost after 221500 iterations is: 2.9451784364112252\n",
      "cost after 222000 iterations is: 2.937634001031866\n",
      "cost after 222500 iterations is: 2.930141969066873\n",
      "cost after 223000 iterations is: 2.922702014305895\n",
      "cost after 223500 iterations is: 2.9153138082376087\n",
      "cost after 224000 iterations is: 2.9079770201124773\n",
      "cost after 224500 iterations is: 2.900691317007656\n",
      "cost after 225000 iterations is: 2.8934563638942143\n",
      "cost after 225500 iterations is: 2.886271823706361\n",
      "cost after 226000 iterations is: 2.879137357412762\n",
      "cost after 226500 iterations is: 2.872052624089805\n",
      "cost after 227000 iterations is: 2.8650172809965944\n",
      "cost after 227500 iterations is: 2.8580309836516324\n",
      "cost after 228000 iterations is: 2.851093385911105\n",
      "cost after 228500 iterations is: 2.84420414004847\n",
      "cost after 229000 iterations is: 2.8373628968352893\n",
      "cost after 229500 iterations is: 2.8305693056232246\n",
      "cost after 230000 iterations is: 2.8238230144268046\n",
      "cost after 230500 iterations is: 2.817123670007085\n",
      "cost after 231000 iterations is: 2.810470917955759\n",
      "cost after 231500 iterations is: 2.8038644027798174\n",
      "cost after 232000 iterations is: 2.797303767986232\n",
      "cost after 232500 iterations is: 2.7907886561670128\n",
      "cost after 233000 iterations is: 2.784318709083901\n",
      "cost after 233500 iterations is: 2.7778935677530043\n",
      "cost after 234000 iterations is: 2.7715128725288647\n",
      "cost after 234500 iterations is: 2.7651762631881343\n",
      "cost after 235000 iterations is: 2.758883379012336\n",
      "cost after 235500 iterations is: 2.752633858869985\n",
      "cost after 236000 iterations is: 2.746427341297477\n",
      "cost after 236500 iterations is: 2.740263464579027\n",
      "cost after 237000 iterations is: 2.7341418668252664\n",
      "cost after 237500 iterations is: 2.7280621860504555\n",
      "cost after 238000 iterations is: 2.722024060248155\n",
      "cost after 238500 iterations is: 2.7160271274654266\n",
      "cost after 239000 iterations is: 2.7100710258751635\n",
      "cost after 239500 iterations is: 2.704155393846719\n",
      "cost after 240000 iterations is: 2.6982798700145487\n",
      "cost after 240500 iterations is: 2.692444093345021\n",
      "cost after 241000 iterations is: 2.686647703201017\n",
      "cost after 241500 iterations is: 2.6808903394044914\n",
      "cost after 242000 iterations is: 2.6751716422968643\n",
      "cost after 242500 iterations is: 2.6694912527971115\n",
      "cost after 243000 iterations is: 2.66384881245769\n",
      "cost after 243500 iterations is: 2.65824396351794\n",
      "cost after 244000 iterations is: 2.652676348955314\n",
      "cost after 244500 iterations is: 2.647145612534098\n",
      "cost after 245000 iterations is: 2.6416513988517054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 245500 iterations is: 2.636193353382587\n",
      "cost after 246000 iterations is: 2.630771122519646\n",
      "cost after 246500 iterations is: 2.625384353613091\n",
      "cost after 247000 iterations is: 2.620032695006972\n",
      "cost after 247500 iterations is: 2.6147157960731318\n",
      "cost after 248000 iterations is: 2.6094333072426097\n",
      "cost after 248500 iterations is: 2.604184880034744\n",
      "cost after 249000 iterations is: 2.5989701670836305\n",
      "cost after 249500 iterations is: 2.5937888221622005\n",
      "cost after 250000 iterations is: 2.5886405002039172\n",
      "cost after 250500 iterations is: 2.5835248573218754\n",
      "cost after 251000 iterations is: 2.5784415508257257\n",
      "cost after 251500 iterations is: 2.5733902392359664\n",
      "cost after 252000 iterations is: 2.568370582296137\n",
      "cost after 252500 iterations is: 2.563382240982529\n",
      "cost after 253000 iterations is: 2.5584248775115843\n",
      "cost after 253500 iterations is: 2.5534981553452023\n",
      "cost after 254000 iterations is: 2.548601739193654\n",
      "cost after 254500 iterations is: 2.5437352950163583\n",
      "cost after 255000 iterations is: 2.538898490020557\n",
      "cost after 255500 iterations is: 2.534090992657815\n",
      "cost after 256000 iterations is: 2.5293124726185203\n",
      "cost after 256500 iterations is: 2.524562600824267\n",
      "cost after 257000 iterations is: 2.5198410494183374\n",
      "cost after 257500 iterations is: 2.5151474917541545\n",
      "cost after 258000 iterations is: 2.5104816023819447\n",
      "cost after 258500 iterations is: 2.505843057033496\n",
      "cost after 259000 iterations is: 2.5012315326050834\n",
      "cost after 259500 iterations is: 2.4966467071386695\n",
      "cost after 260000 iterations is: 2.4920882598014704\n",
      "cost after 260500 iterations is: 2.4875558708636656\n",
      "cost after 261000 iterations is: 2.483049221674757\n",
      "cost after 261500 iterations is: 2.4785679946382038\n",
      "cost after 262000 iterations is: 2.4741118731845413\n",
      "cost after 262500 iterations is: 2.469680541743161\n",
      "cost after 263000 iterations is: 2.4652736857126043\n",
      "cost after 263500 iterations is: 2.4608909914295203\n",
      "cost after 264000 iterations is: 2.456532146136406\n",
      "cost after 264500 iterations is: 2.4521968379479535\n",
      "cost after 265000 iterations is: 2.447884755816418\n",
      "cost after 265500 iterations is: 2.4435955894956845\n",
      "cost after 266000 iterations is: 2.4393290295043832\n",
      "cost after 266500 iterations is: 2.4350847670879743\n",
      "cost after 267000 iterations is: 2.4308624941798342\n",
      "cost after 267500 iterations is: 2.4266619033615413\n",
      "cost after 268000 iterations is: 2.4224826878223054\n",
      "cost after 268500 iterations is: 2.418324541317623\n",
      "cost after 269000 iterations is: 2.41418715812726\n",
      "cost after 269500 iterations is: 2.410070233012666\n",
      "cost after 270000 iterations is: 2.4059734611737356\n",
      "cost after 270500 iterations is: 2.401896538205167\n",
      "cost after 271000 iterations is: 2.3978391600523628\n",
      "cost after 271500 iterations is: 2.393801022967127\n",
      "cost after 272000 iterations is: 2.38978182346285\n",
      "cost after 272500 iterations is: 2.385781258269858\n",
      "cost after 273000 iterations is: 2.3817990242903684\n",
      "cost after 273500 iterations is: 2.377834818553593\n",
      "cost after 274000 iterations is: 2.373888338170987\n",
      "cost after 274500 iterations is: 2.3699592802914906\n",
      "cost after 275000 iterations is: 2.366047342057172\n",
      "cost after 275500 iterations is: 2.3621522205592487\n",
      "cost after 276000 iterations is: 2.3582736127944597\n",
      "cost after 276500 iterations is: 2.354411215622177\n",
      "cost after 277000 iterations is: 2.3505647257220175\n",
      "cost after 277500 iterations is: 2.3467338395524457\n",
      "cost after 278000 iterations is: 2.3429182533100947\n",
      "cost after 278500 iterations is: 2.3391176628902954\n",
      "cost after 279000 iterations is: 2.3353317638486595\n",
      "cost after 279500 iterations is: 2.3315602513639186\n",
      "cost after 280000 iterations is: 2.3278028202023826\n",
      "cost after 280500 iterations is: 2.324059164683672\n",
      "cost after 281000 iterations is: 2.320328978648456\n",
      "cost after 281500 iterations is: 2.3166119554277804\n",
      "cost after 282000 iterations is: 2.3129077878146376\n",
      "cost after 282500 iterations is: 2.3092161680375054\n",
      "cost after 283000 iterations is: 2.30553678773639\n",
      "cost after 283500 iterations is: 2.3018693379413135\n",
      "cost after 284000 iterations is: 2.298213509053358\n",
      "cost after 284500 iterations is: 2.2945689908288016\n",
      "cost after 285000 iterations is: 2.290935472366157\n",
      "cost after 285500 iterations is: 2.2873126420963867\n",
      "cost after 286000 iterations is: 2.283700187776733\n",
      "cost after 286500 iterations is: 2.280097796488038\n",
      "cost after 287000 iterations is: 2.27650515463593\n",
      "cost after 287500 iterations is: 2.272921947956081\n",
      "cost after 288000 iterations is: 2.26934786152366\n",
      "cost after 288500 iterations is: 2.2657825797673614\n",
      "cost after 289000 iterations is: 2.2622257864880164\n",
      "cost after 289500 iterations is: 2.258677164882238\n",
      "cost after 290000 iterations is: 2.2551363975710297\n",
      "cost after 290500 iterations is: 2.2516031666339833\n",
      "cost after 291000 iterations is: 2.2480771536488997\n",
      "cost after 291500 iterations is: 2.2445580397373037\n",
      "cost after 292000 iterations is: 2.2410455056159915\n",
      "cost after 292500 iterations is: 2.2375392316549156\n",
      "cost after 293000 iterations is: 2.234038897941445\n",
      "cost after 293500 iterations is: 2.2305441843514826\n",
      "cost after 294000 iterations is: 2.227054770627454\n",
      "cost after 294500 iterations is: 2.2235703364634567\n",
      "cost after 295000 iterations is: 2.2200905615978135\n",
      "cost after 295500 iterations is: 2.2166151259130658\n",
      "cost after 296000 iterations is: 2.213143709543893\n",
      "cost after 296500 iterations is: 2.209675992992746\n",
      "cost after 297000 iterations is: 2.206211657253761\n",
      "cost after 297500 iterations is: 2.2027503839447102\n",
      "cost after 298000 iterations is: 2.199291855447543\n",
      "cost after 298500 iterations is: 2.195835755057204\n",
      "cost after 299000 iterations is: 2.1923817671390933\n",
      "cost after 299500 iterations is: 2.188929577295331\n",
      "cost after 300000 iterations is: 2.185478872539461\n",
      "cost after 300500 iterations is: 2.182029341480083\n",
      "cost after 301000 iterations is: 2.178580674513226\n",
      "cost after 301500 iterations is: 2.1751325640232024\n",
      "cost after 302000 iterations is: 2.1716847045923275\n",
      "cost after 302500 iterations is: 2.1682367932190965\n",
      "cost after 303000 iterations is: 2.1647885295447042\n",
      "cost after 303500 iterations is: 2.161339616087816\n",
      "cost after 304000 iterations is: 2.1578897584874954\n",
      "cost after 304500 iterations is: 2.1544386657535997\n",
      "cost after 305000 iterations is: 2.1509860505249994\n",
      "cost after 305500 iterations is: 2.1475316293346185\n",
      "cost after 306000 iterations is: 2.1440751228814205\n",
      "cost after 306500 iterations is: 2.1406162563086024\n",
      "cost after 307000 iterations is: 2.1371547594876446\n",
      "cost after 307500 iterations is: 2.1336903673076573\n",
      "cost after 308000 iterations is: 2.130222819969438\n",
      "cost after 308500 iterations is: 2.1267518632836113\n",
      "cost after 309000 iterations is: 2.1232772489721694\n",
      "cost after 309500 iterations is: 2.119798734972748\n",
      "cost after 310000 iterations is: 2.116316085744727\n",
      "cost after 310500 iterations is: 2.112829072576422\n",
      "cost after 311000 iterations is: 2.1093374738926265\n",
      "cost after 311500 iterations is: 2.105841075561273\n",
      "cost after 312000 iterations is: 2.102339671198552\n",
      "cost after 312500 iterations is: 2.0988330624714564\n",
      "cost after 313000 iterations is: 2.095321059396525\n",
      "cost after 313500 iterations is: 2.091803480634064\n",
      "cost after 314000 iterations is: 2.088280153776478\n",
      "cost after 314500 iterations is: 2.084750915629757\n",
      "cost after 315000 iterations is: 2.081215612486992\n",
      "cost after 315500 iterations is: 2.0776741003928083\n",
      "cost after 316000 iterations is: 2.074126245397512\n",
      "cost after 316500 iterations is: 2.0705719237998923\n",
      "cost after 317000 iterations is: 2.0670110223775424\n",
      "cost after 317500 iterations is: 2.0634434386036835\n",
      "cost after 318000 iterations is: 2.05986908084913\n",
      "cost after 318500 iterations is: 2.0562878685687114\n",
      "cost after 319000 iterations is: 2.0526997324708853\n",
      "cost after 319500 iterations is: 2.0491046146696488\n",
      "cost after 320000 iterations is: 2.0455024688177708\n",
      "cost after 320500 iterations is: 2.041893260220555\n",
      "cost after 321000 iterations is: 2.038276965929327\n",
      "cost after 321500 iterations is: 2.0346535748137313\n",
      "cost after 322000 iterations is: 2.0310230876124504\n",
      "cost after 322500 iterations is: 2.0273855169615995\n",
      "cost after 323000 iterations is: 2.0237408874002747\n",
      "cost after 323500 iterations is: 2.020089235352982\n",
      "cost after 324000 iterations is: 2.0164306090885793\n",
      "cost after 324500 iterations is: 2.0127650686554546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 325000 iterations is: 2.009092685793024\n",
      "cost after 325500 iterations is: 2.0054135438193077\n",
      "cost after 326000 iterations is: 2.001727737494916\n",
      "cost after 326500 iterations is: 1.998035372863487\n",
      "cost after 327000 iterations is: 1.9943365670690658\n",
      "cost after 327500 iterations is: 1.990631448150669\n",
      "cost after 328000 iterations is: 1.986920154814657\n",
      "cost after 328500 iterations is: 1.9832028361855882\n",
      "cost after 329000 iterations is: 1.979479651536187\n",
      "cost after 329500 iterations is: 1.9757507699972345\n",
      "cost after 330000 iterations is: 1.9720163702484572\n",
      "cost after 330500 iterations is: 1.9682766401911713\n",
      "cost after 331000 iterations is: 1.9645317766039407\n",
      "cost after 331500 iterations is: 1.960781984782164\n",
      "cost after 332000 iterations is: 1.9570274781631471\n",
      "cost after 332500 iterations is: 1.9532684779374723\n",
      "cost after 333000 iterations is: 1.9495052126483292\n",
      "cost after 333500 iterations is: 1.9457379177799867\n",
      "cost after 334000 iterations is: 1.9419668353366888\n",
      "cost after 334500 iterations is: 1.9381922134136382\n",
      "cost after 335000 iterations is: 1.9344143057611414\n",
      "cost after 335500 iterations is: 1.9306333713436818\n",
      "cost after 336000 iterations is: 1.9268496738949594\n",
      "cost after 336500 iterations is: 1.9230634814706293\n",
      "cost after 337000 iterations is: 1.9192750659999118\n",
      "cost after 337500 iterations is: 1.9154847028375674\n",
      "cost after 338000 iterations is: 1.91169267031737\n",
      "cost after 338500 iterations is: 1.9078992493086266\n",
      "cost after 339000 iterations is: 1.9041047227767889\n",
      "cost after 339500 iterations is: 1.9003093753494111\n",
      "cost after 340000 iterations is: 1.8965134928886207\n",
      "cost after 340500 iterations is: 1.8927173620710607\n",
      "cost after 341000 iterations is: 1.888921269976617\n",
      "cost after 341500 iterations is: 1.885125503686344\n",
      "cost after 342000 iterations is: 1.8813303498911327\n",
      "cost after 342500 iterations is: 1.8775360945113502\n",
      "cost after 343000 iterations is: 1.8737430223285008\n",
      "cost after 343500 iterations is: 1.8699514166295494\n",
      "cost after 344000 iterations is: 1.8661615588643068\n",
      "cost after 344500 iterations is: 1.8623737283166708\n",
      "cost after 345000 iterations is: 1.8585882017898836\n",
      "cost after 345500 iterations is: 1.8548052533063972\n",
      "cost after 346000 iterations is: 1.8510251538225237\n",
      "cost after 346500 iterations is: 1.8472481709581055\n",
      "cost after 347000 iterations is: 1.8434745687414067\n",
      "cost after 347500 iterations is: 1.8397046073694043\n",
      "cost after 348000 iterations is: 1.8359385429832378\n",
      "cost after 348500 iterations is: 1.8321766274592086\n",
      "cost after 349000 iterations is: 1.8284191082148757\n",
      "cost after 349500 iterations is: 1.8246662280303512\n",
      "cost after 350000 iterations is: 1.8209182248845943\n",
      "cost after 350500 iterations is: 1.8171753318063213\n",
      "cost after 351000 iterations is: 1.8134377767395857\n",
      "cost after 351500 iterations is: 1.8097057824233607\n",
      "cost after 352000 iterations is: 1.805979566285175\n",
      "cost after 352500 iterations is: 1.8022593403480687\n",
      "cost after 353000 iterations is: 1.7985453111508005\n",
      "cost after 353500 iterations is: 1.7948376796807244\n",
      "cost after 354000 iterations is: 1.7911366413189034\n",
      "cost after 354500 iterations is: 1.787442385797122\n",
      "cost after 355000 iterations is: 1.783755097166248\n",
      "cost after 355500 iterations is: 1.7800749537754847\n",
      "cost after 356000 iterations is: 1.7764021282620408\n",
      "cost after 356500 iterations is: 1.772736787550754\n",
      "cost after 357000 iterations is: 1.7690790928631572\n",
      "cost after 357500 iterations is: 1.765429199735498\n",
      "cost after 358000 iterations is: 1.761787258045194\n",
      "cost after 358500 iterations is: 1.7581534120453224\n",
      "cost after 359000 iterations is: 1.7545278004065508\n",
      "cost after 359500 iterations is: 1.750910556266129\n",
      "cost after 360000 iterations is: 1.747301807283398\n",
      "cost after 360500 iterations is: 1.7437016757014296\n",
      "cost after 361000 iterations is: 1.7401102784142015\n",
      "cost after 361500 iterations is: 1.7365277270391515\n",
      "cost after 362000 iterations is: 1.7329541279943428\n",
      "cost after 362500 iterations is: 1.729389582580043\n",
      "cost after 363000 iterations is: 1.7258341870643015\n",
      "cost after 363500 iterations is: 1.7222880327719945\n",
      "cost after 364000 iterations is: 1.718751206177213\n",
      "cost after 364500 iterations is: 1.7152237889983077\n",
      "cost after 365000 iterations is: 1.7117058582955902\n",
      "cost after 365500 iterations is: 1.7081974865710698\n",
      "cost after 366000 iterations is: 1.7046987418701545\n",
      "cost after 366500 iterations is: 1.701209687884721\n",
      "cost after 367000 iterations is: 1.6977303840577176\n",
      "cost after 367500 iterations is: 1.6942608856884147\n",
      "cost after 368000 iterations is: 1.6908012440387123\n",
      "cost after 368500 iterations is: 1.6873515064397202\n",
      "cost after 369000 iterations is: 1.6839117163987198\n",
      "cost after 369500 iterations is: 1.680481913706101\n",
      "cost after 370000 iterations is: 1.6770621345421965\n",
      "cost after 370500 iterations is: 1.6736524115837892\n",
      "cost after 371000 iterations is: 1.6702527741100297\n",
      "cost after 371500 iterations is: 1.666863248107743\n",
      "cost after 372000 iterations is: 1.6634838563759327\n",
      "cost after 372500 iterations is: 1.6601146186292053\n",
      "cost after 373000 iterations is: 1.656755551600233\n",
      "cost after 373500 iterations is: 1.6534066691409024\n",
      "cost after 374000 iterations is: 1.6500679823221989\n",
      "cost after 374500 iterations is: 1.6467394995326297\n",
      "cost after 375000 iterations is: 1.6434212265752148\n",
      "cost after 375500 iterations is: 1.6401131667627806\n",
      "cost after 376000 iterations is: 1.6368153210117085\n",
      "cost after 376500 iterations is: 1.6335276879338725\n",
      "cost after 377000 iterations is: 1.630250263926846\n",
      "cost after 377500 iterations is: 1.6269830432622938\n",
      "cost after 378000 iterations is: 1.6237260181724806\n",
      "cost after 378500 iterations is: 1.6204791789348638\n",
      "cost after 379000 iterations is: 1.6172425139547877\n",
      "cost after 379500 iterations is: 1.614016009846229\n",
      "cost after 380000 iterations is: 1.610799651510514\n",
      "cost after 380500 iterations is: 1.6075934222131798\n",
      "cost after 381000 iterations is: 1.6043973036586567\n",
      "cost after 381500 iterations is: 1.6012112760631914\n",
      "cost after 382000 iterations is: 1.5980353182255778\n",
      "cost after 382500 iterations is: 1.5948694075959977\n",
      "cost after 383000 iterations is: 1.591713520342889\n",
      "cost after 383500 iterations is: 1.5885676314178203\n",
      "cost after 384000 iterations is: 1.585431714618428\n",
      "cost after 384500 iterations is: 1.5823057426493932\n",
      "cost after 385000 iterations is: 1.5791896871815536\n",
      "cost after 385500 iterations is: 1.5760835189091098\n",
      "cost after 386000 iterations is: 1.5729872076049016\n",
      "cost after 386500 iterations is: 1.5699007221739543\n",
      "cost after 387000 iterations is: 1.5668240307051307\n",
      "cost after 387500 iterations is: 1.563757100521016\n",
      "cost after 388000 iterations is: 1.560699898226118\n",
      "cost after 388500 iterations is: 1.5576523897531764\n",
      "cost after 389000 iterations is: 1.554614540408049\n",
      "cost after 389500 iterations is: 1.5515863149126836\n",
      "cost after 390000 iterations is: 1.5485676774466512\n",
      "cost after 390500 iterations is: 1.5455585916870265\n",
      "cost after 391000 iterations is: 1.542559020846718\n",
      "cost after 391500 iterations is: 1.5395689277113174\n",
      "cost after 392000 iterations is: 1.5365882746744668\n",
      "cost after 392500 iterations is: 1.5336170237718143\n",
      "cost after 393000 iterations is: 1.530655136713516\n",
      "cost after 393500 iterations is: 1.5277025749154163\n",
      "cost after 394000 iterations is: 1.524759299528925\n",
      "cost after 394500 iterations is: 1.52182527146957\n",
      "cost after 395000 iterations is: 1.5189004514443392\n",
      "cost after 395500 iterations is: 1.515984799977736\n",
      "cost after 396000 iterations is: 1.5130782774367695\n",
      "cost after 396500 iterations is: 1.5101808440547262\n",
      "cost after 397000 iterations is: 1.5072924599538562\n",
      "cost after 397500 iterations is: 1.5044130851669906\n",
      "cost after 398000 iterations is: 1.5015426796581484\n",
      "cost after 398500 iterations is: 1.4986812033420545\n",
      "cost after 399000 iterations is: 1.495828616102872\n",
      "cost after 399500 iterations is: 1.4929848778117858\n"
     ]
    }
   ],
   "source": [
    "# We will just run the network this time. We have experience of building a network already.\n",
    "epochs = 400000\n",
    "lr = 0.1\n",
    "\n",
    "for i in range(epochs):\n",
    "    # forward propagation\n",
    "\n",
    "    Z1 = W1.dot(X) + B1\n",
    "    A1 = sigmoid(Z1)\n",
    "\n",
    "    Z2 = W2.dot(A1) + B2\n",
    "    # This time, the activation function is softmax function\n",
    "    A2 = softmax(Z2)\n",
    "    \n",
    "    # print cost\n",
    "    cost = logCostMulti(A2,Y)\n",
    "    if i%500 == 0:\n",
    "        print(\"cost after\",str(i),\"iterations is:\",cost)\n",
    "    costs.append(cost)\n",
    "    \n",
    "    # backprop\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m) * (dZ2.dot(A1.T))\n",
    "    dB2 = (1/m) * (dZ2.mean(axis = 1,keepdims = True))\n",
    "\n",
    "    dZ1 = (W2.T).dot(dZ2) * A1 * (1 - A1)\n",
    "    dW1 = (1/m) * (dZ1.dot(X.T))\n",
    "    dB1 = (1/m) * (dZ1.mean(axis = 1,keepdims = True)) \n",
    "    \n",
    "    # weight update\n",
    "    W1 = W1 - lr * dW1\n",
    "    W2 = W2 - lr * dW2\n",
    "\n",
    "    B1 = B1 - lr * dB1\n",
    "    B2 = B2 - lr * dB2\n",
    "    \n",
    "# Brace yourself. This is going to take time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's infer the predictions now\n",
    "pred = np.zeros(A2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred s an array of zeros right now\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reminding you that A2 contains output for 150 samples \n",
    "A2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(A2.shape[1]):\n",
    "\n",
    "    # So we just say that our prediction is equal to category of corresponding index of output node that gives the maximum output\n",
    "    val = np.argmax(A2[:,i])\n",
    "    pred[i] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yIris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perfect prediction yet again\n",
    "pred - yIris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An exercise to try: Split this data into test and train. Train a network on train data and see how well the network does on test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
